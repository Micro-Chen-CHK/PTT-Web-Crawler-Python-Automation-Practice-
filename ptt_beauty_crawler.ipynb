{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "564fcec1-42d3-403a-923d-86d3af2afdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in d:\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26d7c461-ec66-4e4c-8ef0-3f8bc2445bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ PTT çˆ¬èŸ²å•Ÿå‹•ä¸­ (æº«å’Œç‰ˆ)...\n",
      "\n",
      "ğŸ“‚ æ­£åœ¨è®€å–ç¬¬ 1 é ...\n",
      "æ­£åœ¨è™•ç†ï¼š[æ­£å¦¹] å¯æ„›å°é›€æ–‘\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] W8DNz4rQ_o.jpg\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] 2Nc0gZez_o.jpg\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] hwt5R5Mi_o.jpg\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] 3bQfpHJm_o.jpg\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] RQu9Cb6P_o.jpg\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] qSXbU2W0_o.jpg\n",
      "   â˜• ä¼‘æ¯ 2.8 ç§’...\n",
      "æ­£åœ¨è™•ç†ï¼š[æ­£å¦¹] estelle.belmont,æ„›åˆ†äº«å¥èº«çš„å¥³å­©\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] wihDlpCn_o.jpg\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] 2g6TcW0q_o.jpg\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] OermNaW4_o.gif\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] wkbNjAdc_o.jpg\n",
      "   âŒ [ä¸‹è¼‰éŒ¯èª¤] HTTPSConnectionPool(host='images2.imgbox.com', port=443): Read timed out.\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] UKbb2s1i_o.jpg\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] Kf9AmEKU_o.jpg\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] ySG7JObr_o.gif\n",
      "   âŒ [ä¸‹è¼‰éŒ¯èª¤] HTTPSConnectionPool(host='images2.imgbox.com', port=443): Read timed out.\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] 1jAsK9AB_o.jpg\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] bHmFir0a_o.jpg\n",
      "   â˜• ä¼‘æ¯ 1.4 ç§’...\n",
      "æ­£åœ¨è™•ç†ï¼š[æ­£å¦¹] Cosplay 2452 æ—¥æœ¬ è‰¾èœœè‰äº\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] DfEXo.jpg\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] VGsL7.jpg\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] 8d9Tx.jpg\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] 89IE3.jpg\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] Nfuk1.jpg\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] cgD2r.jpg\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] HXloy.jpg\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] e8dN5uA.png\n",
      "   â˜• ä¼‘æ¯ 1.1 ç§’...\n",
      "æ­£åœ¨è™•ç†ï¼š[æ­£å¦¹] åœ¨å°åŒ—çš„æ›¹è–‡å¨Ÿ ä¸‰å¼µ\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] jIc6lA.jpg\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] 4GHPmo.jpg\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] Pd0l63.jpg\n",
      "   â˜• ä¼‘æ¯ 1.7 ç§’...\n",
      "æ­£åœ¨è™•ç†ï¼š[æ­£å¦¹] éŸ“åœ‹ Hanini\n",
      "   âœ… [ä¸‹è¼‰æˆåŠŸ] Vqvl0BJ.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 104\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124må…¬å‘Š\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m title: \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mæ­£åœ¨è™•ç†ï¼š\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 104\u001b[0m parse_article(link, title)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# æ¯è™•ç†å®Œä¸€ç¯‡æ–‡ç« ï¼Œä¼‘æ¯ 1~3 ç§’ (éš¨æ©Ÿ)\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# é€™æ˜¯é¿å…è¢«é–çš„é—œéµï¼\u001b[39;00m\n\u001b[0;32m    108\u001b[0m wait_time \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 76\u001b[0m, in \u001b[0;36mparse_article\u001b[1;34m(article_url, title)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m href \u001b[38;5;129;01mand\u001b[39;00m href\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(img_extensions):\n\u001b[0;32m     75\u001b[0m         found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m         save_image(href, title)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   (æ­¤æ–‡ç« ç„¡åœ–ç‰‡)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 45\u001b[0m, in \u001b[0;36msave_image\u001b[1;34m(img_url, title)\u001b[0m\n\u001b[0;32m     41\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(folder_name)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# ä¸‹è¼‰åœ–ç‰‡ä¹Ÿè¦æ…¢ä¸€é»\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1.5\u001b[39m)) \n\u001b[0;32m     47\u001b[0m     img_resp \u001b[38;5;241m=\u001b[39m rs\u001b[38;5;241m.\u001b[39mget(img_url, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img_resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "import random  # æ–°å¢éš¨æ©Ÿæ•¸ï¼Œè®“è¡Œç‚ºæ›´åƒçœŸäºº\n",
    "\n",
    "# --- è¨­å®šå€ ---\n",
    "PTT_URL = \"https://www.ptt.cc\"\n",
    "BOARD = \"Beauty\"\n",
    "TARGET_URL = f\"{PTT_URL}/bbs/{BOARD}/index.html\"\n",
    "\n",
    "# å»ºç«‹ä¸€å€‹ Session (åƒæ˜¯ä¸€å€‹æŒçºŒçš„ç€è¦½å™¨è¦–çª—)\n",
    "rs = requests.Session()\n",
    "rs.headers.update({\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "    \"Cookie\": \"over18=1\"\n",
    "})\n",
    "\n",
    "# --- å‡½æ•¸å€ ---\n",
    "def get_soup(url, retries=3):\n",
    "    \"\"\"\n",
    "    å¢åŠ é‡è©¦æ©Ÿåˆ¶ï¼šå¦‚æœå¤±æ•—ï¼Œæœƒç­‰å¾…å¾Œå†è©¦ä¸€æ¬¡\n",
    "    \"\"\"\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            resp = rs.get(url, timeout=10) # è¨­å®šè¶…æ™‚é™åˆ¶\n",
    "            if resp.status_code == 200:\n",
    "                return BeautifulSoup(resp.text, \"html.parser\")\n",
    "            else:\n",
    "                print(f\"âš ï¸ ç¶²é å›æ‡‰ç•°å¸¸: {resp.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ é€£ç·šå¤±æ•— (å˜—è©¦ {i+1}/{retries}): {e}\")\n",
    "            time.sleep(3) # å¤±æ•—æ™‚ä¼‘æ¯ 3 ç§’å†è©¦\n",
    "            \n",
    "    print(\"âŒ ç„¡æ³•å–å¾—ç¶²é ï¼Œè·³éæ­¤é€£çµ\")\n",
    "    return None\n",
    "\n",
    "def save_image(img_url, title):\n",
    "    folder_name = \"downloaded_images/\" + title.replace(\"/\", \"_\").replace(\":\", \"_\").replace(\"?\", \"\")\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    \n",
    "    try:\n",
    "        # ä¸‹è¼‰åœ–ç‰‡ä¹Ÿè¦æ…¢ä¸€é»\n",
    "        time.sleep(random.uniform(0.5, 1.5)) \n",
    "        \n",
    "        img_resp = rs.get(img_url, stream=True, timeout=10)\n",
    "        if img_resp.status_code == 200:\n",
    "            file_name = img_url.split(\"/\")[-1]\n",
    "            file_path = f\"{folder_name}/{file_name}\"\n",
    "            \n",
    "            with open(file_path, \"wb\") as f:\n",
    "                for chunk in img_resp.iter_content(1024):\n",
    "                    f.write(chunk)\n",
    "            print(f\"   âœ… [ä¸‹è¼‰æˆåŠŸ] {file_name}\")\n",
    "        else:\n",
    "            print(f\"   âš ï¸ [åœ–ç‰‡å¤±æ•ˆ] {img_url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ [ä¸‹è¼‰éŒ¯èª¤] {e}\")\n",
    "\n",
    "def parse_article(article_url, title):\n",
    "    soup = get_soup(article_url)\n",
    "    if not soup: return\n",
    "    \n",
    "    main_content = soup.find(id=\"main-content\")\n",
    "    if not main_content: return\n",
    "    \n",
    "    links = main_content.find_all(\"a\")\n",
    "    img_extensions = ('.jpg', '.jpeg', '.png', '.gif')\n",
    "    \n",
    "    found = False\n",
    "    for link in links:\n",
    "        href = link.get(\"href\")\n",
    "        if href and href.lower().endswith(img_extensions):\n",
    "            found = True\n",
    "            save_image(href, title)\n",
    "            \n",
    "    if not found:\n",
    "        print(\"   (æ­¤æ–‡ç« ç„¡åœ–ç‰‡)\")\n",
    "\n",
    "# --- ä¸»åŸ·è¡Œå€ ---\n",
    "print(\"ğŸš€ PTT çˆ¬èŸ²å•Ÿå‹•ä¸­ (æº«å’Œç‰ˆ)...\")\n",
    "current_url = TARGET_URL\n",
    "pages_to_crawl = 1 \n",
    "\n",
    "for i in range(pages_to_crawl):\n",
    "    print(f\"\\nğŸ“‚ æ­£åœ¨è®€å–ç¬¬ {i+1} é ...\")\n",
    "    soup = get_soup(current_url)\n",
    "    if not soup: \n",
    "        print(\"ç„¡æ³•è®€å–åˆ—è¡¨é ï¼Œç¨‹å¼çµ‚æ­¢ã€‚\")\n",
    "        break\n",
    "        \n",
    "    articles = soup.find_all(\"div\", class_=\"r-ent\")\n",
    "    for article in articles:\n",
    "        title_div = article.find(\"div\", class_=\"title\")\n",
    "        if not title_div.a: continue\n",
    "        \n",
    "        title = title_div.a.text\n",
    "        link = PTT_URL + title_div.a[\"href\"]\n",
    "        \n",
    "        if \"å…¬å‘Š\" in title: continue\n",
    "            \n",
    "        print(f\"æ­£åœ¨è™•ç†ï¼š{title}\")\n",
    "        parse_article(link, title)\n",
    "        \n",
    "        # æ¯è™•ç†å®Œä¸€ç¯‡æ–‡ç« ï¼Œä¼‘æ¯ 1~3 ç§’ (éš¨æ©Ÿ)\n",
    "        # é€™æ˜¯é¿å…è¢«é–çš„é—œéµï¼\n",
    "        wait_time = random.uniform(1, 3)\n",
    "        print(f\"   â˜• ä¼‘æ¯ {wait_time:.1f} ç§’...\")\n",
    "        time.sleep(wait_time)\n",
    "        \n",
    "    controls = soup.find(\"div\", class_=\"btn-group-paging\")\n",
    "    try:\n",
    "        prev_link = controls.find_all(\"a\")[1][\"href\"]\n",
    "        current_url = PTT_URL + prev_link\n",
    "    except:\n",
    "        print(\"æ‰¾ä¸åˆ°ä¸Šä¸€é æŒ‰éˆ•ï¼Œå¯èƒ½å·²åˆ°ç›¡é ­ã€‚\")\n",
    "        break\n",
    "\n",
    "print(\"\\nğŸ‰ ä»»å‹™å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f10a551-c4b5-4ae8-a3a1-01032f1b3841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
